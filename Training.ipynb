{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import d2l\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file_name = \"train_data.csv\"\n",
    "test_data_file_name = \"test_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files ...\n",
      "train_data.csv ... finished (1/2)\n",
      "test_data.csv ... finished (2/2)\n",
      "File loading completed!\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "print(\"Reading files ...\")\n",
    "try:\n",
    "    print(train_data_file_name + \" ... \", end = \"\")\n",
    "    train = pd.read_csv(train_data_file_name)\n",
    "    print(\"finished (1/2)\")\n",
    "    print(test_data_file_name + \" ... \", end = \"\")\n",
    "    test = pd.read_csv(test_data_file_name)\n",
    "    print(\"finished (2/2)\")\n",
    "    print(\"File loading completed!\")\n",
    "except FileNotFoundError as fnf_error:\n",
    "    print(fnf_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15220, 214)\n",
      "(10106, 214)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data size: [14000, 210]\n",
      "validate_data size: [1220, 210]\n",
      "testing_data size: [10106, 210]\n",
      "training_label size: [14000, 2]\n",
      "validate_label size: [1220, 2]\n"
     ]
    }
   ],
   "source": [
    "train_total_size = 15220\n",
    "training_size = 14000\n",
    "validate_size = train_total_size - training_size\n",
    "testing_size = 10106\n",
    "\n",
    "training_data = torch.FloatTensor(train.iloc[: training_size, 4 :].values)\n",
    "validate_data = torch.FloatTensor(train.iloc[training_size :, 4 :].values)\n",
    "testing_data = torch.FloatTensor(test.iloc[:, 4 :].values)\n",
    "training_label = torch.FloatTensor(train.iloc[: training_size, [2, 3]].values)\n",
    "validate_label = torch.FloatTensor(train.iloc[training_size :, [2, 3]].values)\n",
    "print(\"training_data size:\", list(training_data.shape))\n",
    "print(\"validate_data size:\", list(validate_data.shape))\n",
    "print(\"testing_data size:\", list(testing_data.shape))\n",
    "print(\"training_label size:\", list(training_label.shape))\n",
    "print(\"validate_label size:\", list(validate_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden1_size, hidden2_size, output_size = 210, 514, 128, 2\n",
    "batch_size = 14000\n",
    "Epchs = 651\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):        \n",
    "        super(myNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden1_size, hidden2_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden2_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out.float()\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = myNet(input_size, hidden1_size, hidden2_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myNet(\n",
      "  (fc1): Linear(in_features=210, out_features=514, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=514, out_features=128, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "loss_funtion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    features, labels = data_arrays\n",
    "    num_examples = len(labels)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    array = []\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = torch.tensor(indices[i : min(i + batch_size, num_examples - 1)])\n",
    "        minibatch_features = features.index_select(0, batch_indices)\n",
    "        minibatch_labels = labels.index_select(0, batch_indices)\n",
    "        array.append((minibatch_features, minibatch_labels))\n",
    "    train_loader = iter(array)\n",
    "    return train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch  0  is  tensor(1.6748)\n",
      "loss for epoch  65  is  tensor(0.0986)\n",
      "loss for epoch  130  is  tensor(0.0779)\n",
      "loss for epoch  195  is  tensor(0.0649)\n",
      "loss for epoch  260  is  tensor(0.0579)\n",
      "loss for epoch  325  is  tensor(0.0517)\n",
      "loss for epoch  390  is  tensor(0.0477)\n",
      "loss for epoch  455  is  tensor(0.0456)\n",
      "loss for epoch  520  is  tensor(0.0413)\n",
      "loss for epoch  585  is  tensor(0.0400)\n",
      "loss for epoch  650  is  tensor(0.0398)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(Epchs):\n",
    "    data_iter = load_array((training_data, training_label), batch_size)\n",
    "    for batch_X, batch_y in data_iter:\n",
    "        net.zero_grad()\n",
    "        output = net(batch_X)\n",
    "        loss = loss_funtion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % ((Epchs - 1) / 10) == 0:\n",
    "        print(\"loss for epoch \",epoch, \" is \", loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14000, 2])\n",
      "loss for train_data is:  tensor(0.0396)\n",
      "AUC is:  0.9682596709342418\n"
     ]
    }
   ],
   "source": [
    "train_result = net(training_data)\n",
    "print(train_result.shape)\n",
    "print(\"loss for train_data is: \", loss_funtion(train_result, training_label).data)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(training_label.data.numpy()[:, 0], train_result.data.numpy()[:, 0], pos_label=1)\n",
    "train_auc = metrics.auc(fpr, tpr)\n",
    "print(\"AUC is: \", train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1220, 2])\n",
      "loss for train_data is:  tensor(0.2323)\n",
      "AUC is:  0.5758459627329193\n"
     ]
    }
   ],
   "source": [
    "result = net(validate_data)\n",
    "print(result.shape)\n",
    "print(\"loss for train_data is: \", loss_funtion(result, validate_label).data)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(validate_label.data.numpy()[:, 0], result.data.numpy()[:, 0], pos_label=1)\n",
    "validate_auc = metrics.auc(fpr, tpr)\n",
    "print(\"AUC is: \", validate_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
